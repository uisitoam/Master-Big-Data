\babel@toc {english}{}\relax 
\contentsline {chapter}{Contents}{ii}{chapter*.1}%
\contentsline {chapter}{\numberline {1}Aprendizaje estadístico}{1}{chapter.2}%
\contentsline {section}{\numberline {1.1}Motivos para estimar $f$}{1}{section.4}%
\contentsline {subsection}{\numberline {1.1.1}Predicción}{1}{subsection.5}%
\contentsline {subsection}{\numberline {1.1.2}Inferencia}{2}{subsection.8}%
\contentsline {section}{\numberline {1.2}Estimación de $f$}{2}{section.9}%
\contentsline {subsection}{\numberline {1.2.1}Métodos paramétricos}{2}{subsection.10}%
\contentsline {subsection}{\numberline {1.2.2}Métodos no paramétricos}{3}{subsection.13}%
\contentsline {subsection}{\numberline {1.2.3}Exactitud vs interpretabilidad}{3}{subsection.14}%
\contentsline {subsection}{\numberline {1.2.4}Aprendizaje supervisado y no supervisado}{4}{subsection.16}%
\contentsline {subsection}{\numberline {1.2.5}Problemas de regresión y clasificación}{4}{subsection.18}%
\contentsline {chapter}{\numberline {2}Regresión lineal}{5}{chapter.19}%
\contentsline {section}{\numberline {2.1}Regresión lineal simple}{5}{section.21}%
\contentsline {subsection}{\numberline {2.1.1}Estimación de los coeficientes}{5}{subsection.24}%
\contentsline {subsection}{\numberline {2.1.2}Exactitud de la estimación de los coeficientes}{6}{subsection.27}%
\contentsline {subsection}{\numberline {2.1.3}Exactitud del modelo}{7}{subsection.39}%
\contentsline {subsubsection}{Error estándar residual}{7}{section*.40}%
\contentsline {subsubsection}{Estadística $R^2$}{8}{section*.42}%
\contentsline {section}{\numberline {2.2}Regresión multilineal}{8}{section.45}%
\contentsline {subsection}{\numberline {2.2.1}Estimación de los coeficientes}{8}{subsection.48}%
\contentsline {subsection}{\numberline {2.2.2}Algunas preguntas importantes}{9}{subsection.53}%
\contentsline {subsubsection}{Relación entre la respuesta y los preditores}{9}{section*.54}%
\contentsline {subsubsection}{Variables relevantes}{10}{section*.62}%
\contentsline {subsubsection}{Ajuste del modelo}{10}{section*.63}%
\contentsline {subsubsection}{Predicciones}{10}{section*.65}%
\contentsline {subsection}{\numberline {2.2.3}Problemas potenciales}{11}{subsection.71}%
\contentsline {section}{\numberline {2.3}Grandes conjuntos de variable correlacionadas}{11}{section.72}%
\contentsline {section}{\numberline {2.4}Métodos de reducción}{11}{section.73}%
\contentsline {subsection}{\numberline {2.4.1}Regresión de Ridge}{12}{subsection.75}%
\contentsline {subsubsection}{Mejora de Ridge sobre mínimos cuadrados}{13}{section*.82}%
\contentsline {subsection}{\numberline {2.4.2}Regresión Lasso}{14}{subsection.84}%
\contentsline {subsubsection}{Propiedad de selección de variables en Lasso}{15}{section*.89}%
\contentsline {subsubsection}{Comparación entre regresión Lasso y Ridge}{17}{section*.90}%
\contentsline {subsection}{\numberline {2.4.3}Selección del parámetro de ajuste}{18}{subsection.93}%
\contentsline {section}{\numberline {2.5}Reducción de dimensión}{18}{section.94}%
\contentsline {subsection}{\numberline {2.5.1}Análisis de componentes principales}{19}{subsection.95}%
\contentsline {subsubsection}{Una única muestra}{19}{section*.96}%
\contentsline {subsubsection}{n muestras}{19}{section*.101}%
\contentsline {subsection}{\numberline {2.5.2}Regresión de componentes principales}{20}{subsection.106}%
\contentsline {subsection}{\numberline {2.5.3}Consideraciones en PCA}{20}{subsection.108}%
\contentsline {subsubsection}{Escalado de variables}{20}{section*.109}%
\contentsline {subsubsection}{Unicidad de las componentes principales}{21}{section*.111}%
\contentsline {chapter}{\numberline {3}Clasificacion}{22}{chapter.112}%
\contentsline {section}{\numberline {3.1}El entorno de clasificación}{22}{section.113}%
\contentsline {subsection}{\numberline {3.1.1}El clasificador de Bayes}{23}{subsection.116}%
\contentsline {subsection}{\numberline {3.1.2}¿Por qué no regresión lineal?}{24}{subsection.121}%
\contentsline {section}{\numberline {3.2}Regresión logística}{26}{section.123}%
\contentsline {subsection}{\numberline {3.2.1}Modelo logístico}{26}{subsection.124}%
\contentsline {subsection}{\numberline {3.2.2}Estimación de los coeficientes}{27}{subsection.129}%
\contentsline {subsection}{\numberline {3.2.3}Regresión logística múltiple}{27}{subsection.132}%
\contentsline {subsection}{\numberline {3.2.4}Regresión logística no binaria}{28}{subsection.135}%
\contentsline {section}{\numberline {3.3}Análisis discriminante lineal}{28}{section.136}%
\contentsline {subsection}{\numberline {3.3.1}Teorema de Bayes para clasificación}{28}{subsection.137}%
\contentsline {subsubsection}{Regla de Bayes}{28}{section*.138}%
\contentsline {subsubsection}{Regla de Bayes en problemas de clasificación}{28}{section*.140}%
\contentsline {subsubsection}{Análisis discriminante lineal para $p = 1$}{29}{section*.142}%
\contentsline {subsubsection}{Análisis discriminante lineal para $p > 1$}{31}{section*.151}%
\contentsline {subsubsection}{Análisis discriminante cuadrático}{34}{section*.160}%
\contentsline {chapter}{\numberline {4}Evaluación y selección de modelos}{36}{chapter.163}%
\contentsline {section}{\numberline {4.1}Contexto de regresión}{36}{section.165}%
\contentsline {subsection}{\numberline {4.1.1}Calidad del ajuste}{36}{subsection.167}%
\contentsline {subsection}{\numberline {4.1.2}Compromiso entre \textit {bias} y varianza}{37}{subsection.171}%
\contentsline {section}{\numberline {4.2}Contexto de clasificación}{38}{section.174}%
\contentsline {section}{\numberline {4.3}Métodos de remuestreo}{39}{section.178}%
\contentsline {subsection}{\numberline {4.3.1}Validación cruzada}{40}{subsection.179}%
\contentsline {subsubsection}{Enfoque del Conjunto de Validación}{40}{section*.180}%
\contentsline {subsection}{\numberline {4.3.2}Validación cruzada \textit {Leave-One-Out}}{41}{subsection.183}%
\contentsline {subsection}{\numberline {4.3.3}Validación Cruzada k-Fold}{43}{subsection.190}%
\contentsline {subsection}{\numberline {4.3.4}Compromiso \textit {bias}-varianza para la validación cruzada k-Fold}{43}{subsection.193}%
\contentsline {subsection}{\numberline {4.3.5}Validación Cruzada en Problemas de Clasificación}{45}{subsection.194}%
\contentsline {subsubsection}{Regla de una desviación estándar}{45}{section*.199}%
\contentsline {subsubsection}{Forma correcta de hacer validación cruzada}{45}{section*.200}%
\contentsline {section}{\numberline {4.4}Selección de subconjuntos}{47}{section.201}%
\contentsline {subsection}{\numberline {4.4.1}Selección del mejor subconjunto}{47}{subsection.202}%
\contentsline {subsection}{\numberline {4.4.2}Selección por pasos}{47}{subsection.208}%
\contentsline {subsubsection}{Selección por pasos hacia adelante}{48}{section*.209}%
\contentsline {subsubsection}{Selección por pasos hacia atrás}{48}{section*.215}%
\contentsline {subsubsection}{Modelos híbridos}{49}{section*.221}%
\contentsline {section}{\numberline {4.5}Reduciendo de error}{49}{section.222}%
\contentsline {chapter}{\numberline {5}K vecinos más próximos}{50}{chapter.223}%
\contentsline {section}{\numberline {5.1}Algoritmo KNN}{50}{section.224}%
\contentsline {subsection}{\numberline {5.1.1}Alta dimensionalidad}{52}{subsection.230}%
\contentsline {subsection}{\numberline {5.1.2}Consideraciones computacionales}{53}{subsection.233}%
\contentsline {section}{\numberline {5.2}Ejercicio}{53}{section.234}%
\contentsline {chapter}{\numberline {6}Árboles de decisión. Fundamentos}{54}{chapter.241}%
\contentsline {section}{\numberline {6.1}Árboles de decisión}{54}{section.242}%
\contentsline {subsection}{\numberline {6.1.1}Predicción mediante estratificación del espacio de características}{55}{subsection.246}%
\contentsline {subsection}{\numberline {6.1.2}Poda del árbol}{57}{subsection.253}%
\contentsline {subsection}{\numberline {6.1.3}Árboles de Clasificación}{58}{subsection.263}%
\contentsline {subsection}{\numberline {6.1.4}Predictores categóricos}{62}{subsection.269}%
\contentsline {subsection}{\numberline {6.1.5}Árboles vs Modelos lineales}{62}{subsection.272}%
\contentsline {subsection}{\numberline {6.1.6}Ventajas y desventajas de los árboles}{63}{subsection.276}%
\contentsline {section}{\numberline {6.2}Ejercicio}{63}{section.277}%
\contentsline {chapter}{\numberline {7}Redes neuronales}{65}{chapter.285}%
\contentsline {section}{\numberline {7.1}Introducción}{65}{section.286}%
\contentsline {subsection}{\numberline {7.1.1}Función de activación}{66}{subsection.289}%
\contentsline {subsubsection}{Función sigmoide}{66}{section*.290}%
\contentsline {subsubsection}{Tangente hiperbólica}{66}{section*.294}%
\contentsline {subsubsection}{Función lineal rectificada ReLU}{66}{section*.296}%
\contentsline {subsubsection}{Funciones gaussianas de base radial}{67}{section*.298}%
\contentsline {section}{\numberline {7.2}Modelo de red neuronal}{67}{section.300}%
\contentsline {section}{\numberline {7.3}Arquitecturas}{69}{section.313}%
\contentsline {section}{\numberline {7.4}Funciones de coste o error}{70}{section.318}%
\contentsline {subsection}{\numberline {7.4.1}Logartimo negativo de la verosimilitud}{70}{subsection.319}%
\contentsline {subsection}{\numberline {7.4.2}Suma del error cuadrático}{71}{subsection.322}%
\contentsline {subsection}{\numberline {7.4.3}Entropía cruzada}{71}{subsection.325}%
\contentsline {subsubsection}{Entropía cruzada binaria}{71}{section*.326}%
\contentsline {subsubsection}{Entropía cruzada}{71}{section*.330}%
\contentsline {section}{\numberline {7.5}Ajuste de la red}{72}{section.340}%
\contentsline {subsection}{\numberline {7.5.1}Problema de optimización}{72}{subsection.341}%
\contentsline {subsection}{\numberline {7.5.2}Retropropagación}{74}{subsection.347}%
\contentsline {subsection}{\numberline {7.5.3}Descenso de gradiente}{76}{subsection.362}%
\contentsline {subsection}{\numberline {7.5.4}Inicialización de pesos}{77}{subsection.366}%
\contentsline {subsection}{\numberline {7.5.5}Sobreajuste}{77}{subsection.367}%
\contentsline {subsection}{\numberline {7.5.6}Escalado de las entradas}{77}{subsection.369}%
\contentsline {subsection}{\numberline {7.5.7}Número de unidades ocultas y capas}{78}{subsection.370}%
\contentsline {subsection}{\numberline {7.5.8}Múltiples mínimos}{78}{subsection.371}%
\contentsline {subsection}{\numberline {7.5.9}Velocidad de aprendizaje}{79}{subsection.372}%
\contentsline {subsection}{\numberline {7.5.10}Hiperparámetros}{79}{subsection.376}%
\contentsline {subsection}{\numberline {7.5.11}Optimización}{80}{subsection.377}%
\contentsline {section}{\numberline {7.6}Ejemplo: datos de \textit {ZIP code}}{81}{section.385}%
\contentsline {chapter}{\numberline {8}Máquinas de vectores de soporte}{86}{chapter.391}%
\contentsline {section}{\numberline {8.1}Clasificador de máximo margen}{86}{section.392}%
\contentsline {subsection}{\numberline {8.1.1}Hiperplano}{86}{subsection.393}%
\contentsline {subsection}{\numberline {8.1.2}Clasificación usando un hiperplano separador}{87}{subsection.399}%
\contentsline {subsection}{\numberline {8.1.3}Clasificador de máximo margen}{88}{subsection.406}%
\contentsline {subsection}{\numberline {8.1.4}Construcción del clasificador de máximo margen}{90}{subsection.408}%
\contentsline {subsubsection}{Resolución del problema de optimización}{90}{section*.414}%
\contentsline {subsection}{\numberline {8.1.5}El caso no separable}{93}{subsection.433}%
\contentsline {subsection}{\numberline {8.1.6}Clasificador de vectores de soporte}{94}{subsection.435}%
\contentsline {subsubsection}{Frontera de decisión no lineal}{96}{section*.453}%
\contentsline {section}{\numberline {8.2}Máquinas de vectores de soporte}{96}{section.454}%
\contentsline {section}{\numberline {8.3}SVM de clasificación con de más de dos clases}{99}{section.469}%
\contentsline {section}{\numberline {8.4}SVMs para regresión}{100}{section.473}%
\contentsline {section}{\numberline {8.5}Ejercicio}{101}{section.482}%
\contentsline {chapter}{\numberline {9}Bagging}{139}{chapter.500}%
\contentsline {section}{\numberline {9.1}Introducción}{139}{section.501}%
\contentsline {section}{\numberline {9.2}Random Forest}{140}{section.508}%
\contentsline {subsection}{\numberline {9.2.1}Definición}{141}{subsection.509}%
\contentsline {subsection}{\numberline {9.2.2}Muestras \textit {out of bag}}{144}{subsection.517}%
\contentsline {subsection}{\numberline {9.2.3}Sobreajuste en \textit {random forest}}{144}{subsection.519}%
