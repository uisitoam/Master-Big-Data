\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Máquinas de vectores de soporte}{86}{chapter.391}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Chapter8}{{8}{86}{Máquinas de vectores de soporte}{chapter.391}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Clasificador de máximo margen}{86}{section.392}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Hiperplano}{86}{subsection.393}\protected@file@percent }
\newlabel{eq:9.1}{{8.1}{86}{Hiperplano}{equation.394}{}}
\newlabel{eq:9.2}{{8.2}{86}{Hiperplano}{equation.395}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Hiperplano $1 + 2X_1 + 3X_2 = 0$. La región azul consiste en los puntos tales que $1 + 2X_1 + 3X_2 > 0$, mientras que la región roja consiste en los puntos tales que $1 + 2X_1 + 3X_2 < 0$.}}{87}{figure.caption.398}\protected@file@percent }
\newlabel{fig:9.1}{{8.1}{87}{Hiperplano $1 + 2X_1 + 3X_2 = 0$. La región azul consiste en los puntos tales que $1 + 2X_1 + 3X_2 > 0$, mientras que la región roja consiste en los puntos tales que $1 + 2X_1 + 3X_2 < 0$}{figure.caption.398}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}Clasificación usando un hiperplano separador}{87}{subsection.399}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Izquierda: hay dos clases de observaciones (en distintos colores), cada una con medidas en dos variables. Se muestran tres posibles hiperplanos separadores en negro. Derecha: se muestra un ejemplo de hiperplano separador, los ejemplos que caigan en la zona azul serán clasificados como esa clase, mientras que los que caigan en la región morada, serán clasificados como de esa clase.}}{88}{figure.caption.401}\protected@file@percent }
\newlabel{fig:9.2}{{8.2}{88}{Izquierda: hay dos clases de observaciones (en distintos colores), cada una con medidas en dos variables. Se muestran tres posibles hiperplanos separadores en negro. Derecha: se muestra un ejemplo de hiperplano separador, los ejemplos que caigan en la zona azul serán clasificados como esa clase, mientras que los que caigan en la región morada, serán clasificados como de esa clase}{figure.caption.401}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}Clasificador de máximo margen}{88}{subsection.406}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces Hiperplano de margen máximo.}}{89}{figure.caption.407}\protected@file@percent }
\newlabel{fig:9.3}{{8.3}{89}{Hiperplano de margen máximo}{figure.caption.407}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Construcción del clasificador de máximo margen}{90}{subsection.408}\protected@file@percent }
\newlabel{eq:9.9}{{8.10}{90}{Construcción del clasificador de máximo margen}{equation.409}{}}
\newlabel{eq:9.10}{{8.11}{90}{Construcción del clasificador de máximo margen}{equation.410}{}}
\newlabel{eq:9.11}{{8.12}{90}{Construcción del clasificador de máximo margen}{equation.411}{}}
\@writefile{toc}{\contentsline {subsubsection}{Resolución del problema de optimización}{90}{section*.414}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces Clasificadores de vectores de soporte. El panel izquierdo muestra el caso separable. El límite de decisión es la línea sólida, mientras que las líneas discontinuas delimitan el margen máximo sombreado de ancho $2M = 2/\|\beta \|$. El panel derecho muestra el caso no separable (superposición). Los puntos etiquetados como $\xi ^*_j$ están en el lado incorrecto de su margen por una cantidad $\xi ^*_j = M \xi _j$; los puntos en el lado correcto tienen $\xi ^*_j = 0$, las observaciones que están en el lado incorrecto del margen tienen $\xi _j^* > 0$ y, si $\xi _j^* > 1$, la observación están mal clasificada (en el lado incorrecto del hiperplano). El margen se maximiza sujeto a un presupuesto total $\DOTSB \sum@ \slimits@ \xi _i \leq \text  {constante}$. Por lo tanto, $\DOTSB \sum@ \slimits@ \xi ^*_j$ es la distancia total de los puntos en el lado incorrecto de su margen.}}{91}{figure.caption.417}\protected@file@percent }
\newlabel{fig:12.1}{{8.4}{91}{Clasificadores de vectores de soporte. El panel izquierdo muestra el caso separable. El límite de decisión es la línea sólida, mientras que las líneas discontinuas delimitan el margen máximo sombreado de ancho $2M = 2/\|\beta \|$. El panel derecho muestra el caso no separable (superposición). Los puntos etiquetados como $\xi ^*_j$ están en el lado incorrecto de su margen por una cantidad $\xi ^*_j = M \xi _j$; los puntos en el lado correcto tienen $\xi ^*_j = 0$, las observaciones que están en el lado incorrecto del margen tienen $\xi _j^* > 0$ y, si $\xi _j^* > 1$, la observación están mal clasificada (en el lado incorrecto del hiperplano). El margen se maximiza sujeto a un presupuesto total $\sum \xi _i \leq \text {constante}$. Por lo tanto, $\sum \xi ^*_j$ es la distancia total de los puntos en el lado incorrecto de su margen}{figure.caption.417}{}}
\newlabel{eq:4.50}{{8.24}{92}{Resolución del problema de optimización}{equation.425}{}}
\newlabel{eq:4.51}{{8.25}{92}{Resolución del problema de optimización}{equation.426}{}}
\newlabel{eq:4.52}{{8.27}{92}{Resolución del problema de optimización}{equation.428}{}}
\newlabel{eq:4.53}{{8.28}{92}{Resolución del problema de optimización}{equation.429}{}}
\newlabel{eq:12.77}{{8.31}{93}{Resolución del problema de optimización}{equation.432}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}El caso no separable}{93}{subsection.433}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.5}{\ignorespaces Un conjunto de datos en el que no existe un hiperplano separador.}}{94}{figure.caption.434}\protected@file@percent }
\newlabel{fig:9.4}{{8.5}{94}{Un conjunto de datos en el que no existe un hiperplano separador}{figure.caption.434}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}Clasificador de vectores de soporte}{94}{subsection.435}\protected@file@percent }
\newlabel{eq:12.7}{{8.36}{94}{Clasificador de vectores de soporte}{equation.440}{}}
\newlabel{eq:12.8}{{8.37}{94}{Clasificador de vectores de soporte}{equation.441}{}}
\newlabel{eq:12.9}{{8.39}{95}{Clasificador de vectores de soporte}{equation.443}{}}
\newlabel{eq:12.10}{{8.40}{95}{Clasificador de vectores de soporte}{equation.444}{}}
\newlabel{eq:12.11}{{8.41}{95}{Clasificador de vectores de soporte}{equation.445}{}}
\newlabel{eq:12.12}{{8.42}{95}{Clasificador de vectores de soporte}{equation.446}{}}
\newlabel{eq:12.13}{{8.43}{95}{Clasificador de vectores de soporte}{equation.447}{}}
\newlabel{eq:12.14}{{8.44}{95}{Clasificador de vectores de soporte}{equation.448}{}}
\newlabel{eq:12.15}{{8.45}{95}{Clasificador de vectores de soporte}{equation.449}{}}
\newlabel{eq:12.16}{{8.46}{95}{Clasificador de vectores de soporte}{equation.450}{}}
\newlabel{eq:12.17}{{8.47}{95}{Clasificador de vectores de soporte}{equation.451}{}}
\@writefile{toc}{\contentsline {subsubsection}{Frontera de decisión no lineal}{96}{section*.453}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Máquinas de vectores de soporte}{96}{section.454}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.6}{\ignorespaces Ejemplo de \textit  {kernel} polinómico (grado 3) y \textit  {kernel} radial. En el kernel polinómico, los margenes son los huecos comprendidos entre las líneas discontinuas, donde se encuentran ambas líneas continuas; todos los puntos dentro de estos márgenes son vectores de soporte. Para el caso de la gaussiana es más complicado de ver: básicamente, los puntos que están dentro de los círculos discontinuos son los que están fuera del margen y no son vectores de soporte; el resto, son los vectores de soporte.}}{98}{figure.caption.466}\protected@file@percent }
\newlabel{fig:12.2}{{8.6}{98}{Ejemplo de \textit {kernel} polinómico (grado 3) y \textit {kernel} radial. En el kernel polinómico, los margenes son los huecos comprendidos entre las líneas discontinuas, donde se encuentran ambas líneas continuas; todos los puntos dentro de estos márgenes son vectores de soporte. Para el caso de la gaussiana es más complicado de ver: básicamente, los puntos que están dentro de los círculos discontinuos son los que están fuera del margen y no son vectores de soporte; el resto, son los vectores de soporte}{figure.caption.466}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}SVM de clasificación con de más de dos clases}{99}{section.469}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.4}SVMs para regresión}{100}{section.473}\protected@file@percent }
\newlabel{eq:12.36}{{8.65}{100}{SVMs para regresión}{equation.475}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.7}{\ignorespaces El panel izquierdo muestra la ``insensibilidad'' a $\xi $ de la función de error al usar SVMs para regresión. El panel derecho muestra la función de error usada en la regresión robusta de Huber (en la que no profundizaremos); más allá de $|c|$, la función cambia de cuadrática a lineal. Hay un cambio de notación en esta imagen, $\xi \to \epsilon $.}}{101}{figure.caption.477}\protected@file@percent }
\newlabel{fig:12.8}{{8.7}{101}{El panel izquierdo muestra la ``insensibilidad'' a $\xi $ de la función de error al usar SVMs para regresión. El panel derecho muestra la función de error usada en la regresión robusta de Huber (en la que no profundizaremos); más allá de $|c|$, la función cambia de cuadrática a lineal. Hay un cambio de notación en esta imagen, $\xi \to \epsilon $}{figure.caption.477}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Dataset con valores de $\alpha $}}{102}{table.caption.483}\protected@file@percent }
\newlabel{tab:dataset_alpha}{{8.1}{102}{Dataset con valores de $\alpha $}{table.caption.483}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8.2}{\ignorespaces Valores de $\xi _i$ para cada observación. En rojo, las observaciones mal clasificadas.}}{104}{table.caption.498}\protected@file@percent }
\newlabel{tab:2}{{8.2}{104}{Valores de $\xi _i$ para cada observación. En rojo, las observaciones mal clasificadas}{table.caption.498}{}}
\@setckpt{tex/Chapter8}{
\setcounter{page}{105}
\setcounter{equation}{80}
\setcounter{enumi}{4}
\setcounter{enumii}{2}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{8}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{7}
\setcounter{table}{2}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{parentequation}{0}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{subtable}{0}
\setcounter{BAenumi}{0}
\setcounter{float@type}{8}
\setcounter{theorem}{0}
\setcounter{example}{1}
\setcounter{lemma}{0}
\setcounter{definition}{0}
\setcounter{comentario}{0}
\setcounter{tcbbreakpart}{0}
\setcounter{tcblayer}{0}
\setcounter{tcolorbox@number}{0}
\setcounter{AM@survey}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{0}
\setcounter{maxnames}{2}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{9999}
\setcounter{highnamepenalty}{9999}
\setcounter{lownamepenalty}{5000}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{section@level}{1}
\setcounter{Item}{36}
\setcounter{Hfootnote}{3}
\setcounter{bookmark@seq@number}{102}
}
