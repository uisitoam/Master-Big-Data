\chapter{Chapter 9}\label{Chapter9} 
% chktex-file 8
% chktex-file 12
% chktex-file 13
% chktex-file 44

Vamos a ver redes poco profundas (no m√°s de 2 capas ocultas). Transformamos conjunto de variables capa a capa hasta llegar a un conjunto de variables facilmente separables o regresables por la ultima capa. El resultado del pesado se pasa por una funcion de activacion no lineal. El peso $w_{ij}$ conecta la neurona j de la capa l con la neurona i de la capa l+1. No contamos el bias como neurona, asiq ue en el ejemplo que pone hay 3. El bias es un vector siempre, con dimension $\text{neuronas en esa capa} \times 1$. PAra el caso de la capa de entrada, la activacion es directametne la entrada. 