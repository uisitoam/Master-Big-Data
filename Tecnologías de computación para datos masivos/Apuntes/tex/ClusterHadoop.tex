\chapter{Cluster Hadoop}\label{ChapterCH} 
% chktex-file 8
% chktex-file 12
% chktex-file 13
% chktex-file 44


\begin{lstlisting}[style=terminal]
    ssh -i "hadoop.pem" ubuntu@DNS_publico_NNRM
    ssh -i "hadoop.pem" -fNT -L 9870:localhost:9870 -L 8088:localhost:8088 ubuntu@DNS_publico_NNRM
    ssh -i "hadoop.pem" -fNT -L 8188:localhost:8188 ubuntu@DNS_publico_BKTL
    yarn --daemon start timelineserver #en BKTL
\end{lstlisting}


echo "ip-172-31-13-193.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include
echo "ip-172-31-10-249.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include
echo "ip-172-31-6-138.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include
echo "ip-172-31-1-58.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include ESTE fuera

echo "ip-172-31-1-58.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.exclude
echo "ip-172-31-1-58.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/yarn.exclude


Nuevos:
echo "ip-172-31-4-16.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include
echo "ip-172-31-4-16.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/yarn.include
echo "ip-172-31-0-239.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/dfs.include
echo "ip-172-31-0-239.ec2.internal" >> /opt/bd/hadoop/etc/hadoop/yarn.include


172.31.13.193     /rack1
172.31.10.249     /rack1
172.31.6.138     /rack2
172.31.0.239     /rack3
172.31.4.16     /rack3


TAREA 2:
Cuestion 1: Caben 3: estamos indicando que solo se pueden crear hasta 4 entradas de tipo archivo o directorio en esa ubicación (INCLUYENDO EL PROPIO DIRECTORIO). Al alcanzar la cuota de 4 archivos, el NameNode interrumpe cualquier operación que genere nuevas entradas en ese directorio. Equilibra el uso de recursos del sistema.

Cuestion 2: 

193 - 32 bloques (rack1); 16 - 8 bloques (rack3).

Aparecen 35 bloques under-replicated, 2 perdidos y 1 archivo corrupto. Bloques perdidos 
14. BP-1359368873-172.31.14.95-1729179225409:blk_1073741854_1030 len=67108864 MISSING!
15. BP-1359368873-172.31.14.95-1729179225409:blk_1073741855_1031 len=41943040 MISSING!
Si hay bloques perdidos no se puede recuperar el fichero, ya que no todos los ficheros estan disponibles.


Nuevo datanode: los tres tienen 35 bloques


CUestion 3:
espacio utilizado menor por eficiencia de EC. 

Los datos se dividen en bloques de datos y distribuye entre los datanodes. Da tolerancia a fallos y usa menos espacio.

